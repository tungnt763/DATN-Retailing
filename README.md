# üõçÔ∏è Retail Data Analytics Platform

---

## üß≠ M·ª•c l·ª•c
- [Gi·ªõi thi·ªáu](#gi·ªõi-thi·ªáu)
- [Ki·∫øn tr√∫c h·ªá th·ªëng](#ki·∫øn-tr√∫c-h·ªá-th·ªëng)
- [C√¥ng ngh·ªá s·ª≠ d·ª•ng](#c√¥ng-ngh·ªá-s·ª≠-d·ª•ng)
- [H∆∞·ªõng d·∫´n tri·ªÉn khai](#h∆∞·ªõng-d·∫´n-tri·ªÉn-khai)
- [T√†i kho·∫£n m·∫∑c ƒë·ªãnh](#t√†i-kho·∫£n-m·∫∑c-ƒë·ªãnh)
- [Ghi ch√∫](#ghi-ch√∫)

---

## üéØ Gi·ªõi thi·ªáu

D·ª± √°n x√¢y d·ª±ng h·ªá th·ªëng end-to-end cho ph√©p:
- Thu th·∫≠p d·ªØ li·ªáu b√°n l·∫ª t·ª´ nhi·ªÅu ngu·ªìn (th·ªß c√¥ng ho·∫∑c t·ª± ƒë·ªông).
- L∆∞u tr·ªØ d·ªØ li·ªáu tr√™n GCS.
- X·ª≠ l√Ω b·∫±ng BigQuery, theo c√°c layer: landing ‚Üí staging ‚Üí modeling.
- Ki·ªÉm th·ª≠ ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu b·∫±ng Soda.
- Qu·∫£n l√Ω metadata v√† lineage b·∫±ng DataHub.
- Tr·ª±c quan h√≥a d·ªØ li·ªáu b·∫±ng Apache Superset.

---

## üèóÔ∏è Ki·∫øn tr√∫c h·ªá th·ªëng

![Ki·∫øn tr√∫c h·ªá th·ªëng](images/architecture.png)

---

## ‚öôÔ∏è C√¥ng ngh·ªá s·ª≠ d·ª•ng

- Apache Airflow 2.8.1
- Google Cloud Storage
- BigQuery
- Apache Superset
- DataHub
- Soda
- Docker, Docker Compose
- Python, Pandas

---

## üöÄ H∆∞·ªõng d·∫´n tri·ªÉn khai

### ‚úÖ B∆∞·ªõc 1: Clone repository

```bash
git clone https://github.com/tungnt763/DATN-Retailing.git
cd DATN-Retailing
```

---

### ‚öôÔ∏è B∆∞·ªõc 2: Thi·∫øt l·∫≠p Apache Airflow

#### Thi·∫øt l·∫≠p bi·∫øn m√¥i tr∆∞·ªùng

T·∫°o file `.env` ho·∫∑c export tr·ª±c ti·∫øp:

```bash
OPENEXCHANGE_API_KEY=<openexchange_key>
AIRFLOW__SMTP__SMTP_USER=<user_email>
AIRFLOW__SMTP__SMTP_PASSWORD=<password>
GOOGLE_APPLICATION_CREDENTIALS=<absolute_path_to_service_account.json>
```

#### Build v√† kh·ªüi ƒë·ªông Airflow

```bash
docker compose build
docker compose up -d
```

---

### üîå B∆∞·ªõc 3: T·∫°o k·∫øt n·ªëi trong Airflow

V√†o giao di·ªán Airflow: [http://localhost:8080](http://localhost:8080)

T·∫°o c√°c connection sau:

1. **GCP Connection**

   - Conn ID: `gcp`
   - Conn Type: `Google Cloud`
   - Keyfile Path: `path/to/service_account.json`
   - Retries: `5`

2. **DataHub Connection**

   - Conn ID: `datahub_rest_default`
   - Conn Type: `datahub-rest`
   - Host: `http://datahub-gms:8080`

---

### üìö B∆∞·ªõc 4: Tri·ªÉn khai DataHub

```bash
pip install --upgrade pip wheel setuptools
pip install --upgrade acryl-datahub
datahub version
datahub docker quickstart --quickstart-compose-file DATN-Retailing/datahub/docker-compose.yaml
```

---

### üìä B∆∞·ªõc 5: Tri·ªÉn khai Apache Superset

```bash
git clone https://github.com/apache/superset
cd superset
docker build -f Dockerfile.bigquery -t superset-bigquery:latest .
docker compose -f docker-compose-image-tag.yml up -d
```

---

### üîó B∆∞·ªõc 6: K·∫øt n·ªëi Superset v·ªõi BigQuery

- Truy c·∫≠p Superset t·∫°i [http://localhost:8088](http://localhost:8088)
- Th√™m k·∫øt n·ªëi BigQuery s·ª≠ d·ª•ng `service_account.json`
- Ch·∫°y c√°c file SQL trong th∆∞ m·ª•c `visualization/` ƒë·ªÉ t·∫°o dataset v√† dashboard

---

### üß≤ B∆∞·ªõc 7: C·∫•u h√¨nh ki·ªÉm th·ª≠ d·ªØ li·ªáu v·ªõi Soda

#### 1. T·∫°o t√†i kho·∫£n Soda Cloud & l·∫•y API Key

- Truy c·∫≠p: [https://cloud.soda.io](https://cloud.soda.io)

#### 2. T·∫°o file config cho t·ª´ng layer trong `include/soda/<layer_name>/soda.yml`

```yaml
data_source retail_<layer_name>:
  type: bigquery
  connection:
    account_info_json_path: <path_to_service_account.json>
    auth_scopes:
      - https://www.googleapis.com/auth/bigquery
      - https://www.googleapis.com/auth/cloud-platform
      - https://www.googleapis.com/auth/drive
    project_id: <your_project_id>
    dataset: <layer_name>

soda_cloud:
  host: cloud.soda.io
  api_key_id: <your_soda_api_key_id>
  api_key_secret: <your_soda_api_key_secret>
```

---

### ‚ö° B∆∞·ªõc 8: Thi·∫øt l·∫≠p Cloud Pub/Sub v√† m·ªü c·ªïng Airflow b·∫±ng Ngrok

#### 8.1 T·∫°o trigger Pub/Sub t·ª´ GCS

```bash
gsutil notification create -t gcs-trigger-topic \
  -f json -e OBJECT_FINALIZE gs://your-bucket-name
```

#### 8.2 M·ªü c·ªïng Airflow b·∫±ng Ngrok

```bash
brew install --cask ngrok
ngrok config add-authtoken <your_ngrok_token>
ngrok http http://localhost:8080
```

Ghi l·∫°i ƒë·ªãa ch·ªâ nh∆∞ `https://<random>.ngrok.io` ƒë·ªÉ s·ª≠ d·ª•ng cho b∆∞·ªõc k·∫ø ti·∫øp.

### üåê B∆∞·ªõc 9: Thi·∫øt l·∫≠p Web Application

#### 9.1 Clone repository WebApp

```bash
git clone https://github.com/tungnt763/DATN-WebApp.git
cd DATN-WebApp
```

#### 9.2 Thi·∫øt l·∫≠p Backend (Flask)

1. T·∫°o Client ID tr√™n GCP:
   - Truy c·∫≠p Google Cloud Console ‚Üí OAuth 2.0 Credentials
   - T·∫°o OAuth 2.0 Client ID cho ·ª©ng d·ª•ng web
   - Authorized redirect URI: `http://localhost:3000/login`, `http://localhost:5050/login/google/authorized`

2. C·∫•u h√¨nh m√¥i tr∆∞·ªùng backend:
   ```bash
   cd backend
   touch .env
   ```

   N·ªôi dung file `.env`:
   ```
   GCP_BUCKET_NAME=retailing_data
   GCP_CREDENTIAL_PATH=/path/to/your/service_account.json
   DATABASE_URL=postgresql://airflow:airflow@localhost:5432/airflow
   FLASK_SECRET_KEY=your_flask_secret_key
   GOOGLE_CLIENT_ID=your_google_client_id
   GOOGLE_CLIENT_SECRET=your_google_client_secret
   ALLOWED_GOOGLE_DOMAINS=@gmail.com
   ```

3. Ch·∫°y ·ª©ng d·ª•ng backend:
   ```bash
   flask run --host=0.0.0.0 --port=5050
   ```

#### 9.3 Thi·∫øt l·∫≠p Frontend (React)

1. C·∫•u h√¨nh m√¥i tr∆∞·ªùng:
   ```bash
   cd ../frontend
   touch .env
   ```

   N·ªôi dung `.env`:
   ```
   REACT_APP_GOOGLE_CLIENT_ID=your_google_client_id
   ```

2. Ch·∫°y giao di·ªán web:
   ```bash
   npm install
   npm start
   ```

   Giao di·ªán s·∫Ω ch·∫°y t·∫°i `http://localhost:3000`

#### 9.4 C·∫•u h√¨nh Cloud Function

1. T·∫°o file c·∫•u h√¨nh:
   ```bash
   cd ../cloud-function
   touch .env.yaml
   ```

2. N·ªôi dung file `.env.yaml`:
   ```yaml
   AIRFLOW_API_URL: "https://<ngrok_id>.ngrok.io/api/v1/dags"
   AIRFLOW_API_TOKEN: ""
   USE_BASIC_AUTH: "true"
   BASIC_AUTH_USER: "admin"
   BASIC_AUTH_PASS: "admin"
   ```

3. Tri·ªÉn khai Cloud Function:
   ```bash
   gcloud functions deploy gcs_trigger_dag \
     --runtime python310 \
     --entry-point trigger_dag \
     --trigger-topic gcs-trigger-topic \
     --env-vars-file .env.yaml \
     --region asia-southeast1
   ```

> üí° Cloud Function s·∫Ω ƒë∆∞·ª£c g·ªçi m·ªói khi c√≥ file m·ªõi ƒë·∫øn GCS ƒë·ªÉ k√≠ch ho·∫°t DAG t∆∞∆°ng ·ª©ng qua Airflow API.

#### 9.5 M√¥ ph·ªèng ph√°t sinh d·ªØ li·ªáu POS

ƒê·ªÉ m√¥ ph·ªèng vi·ªác ph√°t sinh d·ªØ li·ªáu t·ª´ h·ªá th·ªëng POS:

```bash
cd backend
python pos_sender/pos_sender.py
```

Script n√†y s·∫Ω t·ª± ƒë·ªông g·ª≠i c√°c file `.csv` l√™n GCS ƒë·ªãnh k·ª≥ (m·ªói 10 gi√¢y ho·∫∑c t√πy ch·ªânh), gi·∫£ l·∫≠p qu√° tr√¨nh ph√°t sinh giao d·ªãch t·ª´ h·ªá th·ªëng POS th·ª±c t·∫ø.

---

## üìÅ C·∫•u tr√∫c th∆∞ m·ª•c

```
DATN-Retailing/
‚îú‚îÄ‚îÄ dags/                       # Airflow DAGs
‚îú‚îÄ‚îÄ datahub/                    # C·∫•u h√¨nh DataHub
‚îú‚îÄ‚îÄ include/
‚îÇ   ‚îî‚îÄ‚îÄ soda/<layer_name>/      # File c·∫•u h√¨nh ki·ªÉm th·ª≠ d·ªØ li·ªáu
‚îú‚îÄ‚îÄ superset/                   # C·∫•u h√¨nh Superset
‚îú‚îÄ‚îÄ visualization/              # SQL t·∫°o dashboard
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Dockerfile
‚îî‚îÄ‚îÄ README.md
```

---

## üìù L∆∞u √Ω quan tr·ªçng

1. ƒê·∫£m b·∫£o t·∫•t c·∫£ c√°c port c·∫ßn thi·∫øt ƒë√£ ƒë∆∞·ª£c m·ªü:
   - Airflow: 8082
   - Superset: 8088
   - DataHub: 9002

2. Ki·ªÉm tra k·∫øt n·ªëi gi·ªØa c√°c service:
   ```bash
   # Ki·ªÉm tra k·∫øt n·ªëi Airflow v·ªõi GCS
   airflow connections test gcp
   
   # Ki·ªÉm tra k·∫øt n·ªëi DataHub
   airflow connections test datahub_rest_default
   ```

3. Backup d·ªØ li·ªáu quan tr·ªçng:
   ```bash
   # Backup Airflow metadata
   docker-compose exec postgres pg_dump -U airflow airflow > airflow_backup.sql
   
   # Backup Superset metadata
   cd superset 
   docker-compose -f docker-compose-image-tag.yaml exec superset superset db backup
   ```

---

## üîê T√†i kho·∫£n m·∫∑c ƒë·ªãnh

| H·ªá th·ªëng         | ƒê∆∞·ªùng d·∫´n              | Username | Password |
|------------------|------------------------|----------|----------|
| Apache Airflow   | http://localhost:8082  | admin    | admin    |
| Superset         | http://localhost:8088  | admin    | admin    |
| DataHub          | http://localhost:9002  | datahub  | datahub  |

---

## üìå Ghi ch√∫

- Pipeline h·ªó tr·ª£ ki·ªÉm th·ª≠ theo layer: landing ‚Üí staging ‚Üí modeling
- C√≥ h·ªó tr·ª£ trigger DAG b·∫±ng Google Cloud Pub/Sub, Google Function khi file m·ªõi ƒë·∫øn

---